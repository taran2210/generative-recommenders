run.model_path = ""
run.scenario_name = "Server"
run.batchsize = 100
run.out_dir = ""
run.output_trace = True
run.data_producer_threads = 8
run.compute_eval = False
run.find_peak_performance = False
run.train_split_percentage = 0.75
run.dev_mode = False

# below will override mlperf rules compliant settings - don't use for official submission
run.duration = None
run.target_qps = 5000
run.max_latency = 0.06
run.num_queries = 30000
run.samples_per_query_multistream = 64
run.max_num_samples = 2048
run.numpy_rand_seed = 123
run.new_path_prefix = "/workspace/temp"
run.dataset_percentage = 0.0625
